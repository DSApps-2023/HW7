{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/DSApps_logo_small.jpg\">\n",
    "\n",
    "# DSApps 2023 @ TAU: Assignment 7\n",
    "\n",
    "### Giora Simchoni\n",
    "\n",
    "### Deep Neural Networks with Keras/Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome\n",
    "\n",
    "Welcome to Assignment 7 in Python!\n",
    "\n",
    "Remember:\n",
    "\n",
    "* You can play with the assignment in Playground mode, but:\n",
    "* Only your private Github repository assigned to you by the course admin will be cloned and graded (Submission mode, see instructions [here](https://github.com/DSApps-2023/Class_Slides/blob/main/Apps_of_DS_HW.pdf))\n",
    "* Like any other University assignment, your work should remain private\n",
    "* You need to `git clone` your private Github repository locally as explained [here](https://github.com/DSApps-2023/Class_Slides/blob/main/Apps_of_DS_HW.pdf)\n",
    "* You need to uncomment the starter code inside the chunk, replace the `### YOUR CODE HERE ###`, run the chunk and see that you're getting the expected result\n",
    "* Pay attention to what you're asked to do and the required output\n",
    "* For example, using a *different* function than the one you were specifically asked to use, will decrease your score (unless you amaze me)\n",
    "* Your notebook should run smoothly from start to end if someone presses in the Jupyter toolbar Kernel --> Restart & Run All\n",
    "* When you're done save the entire notebook into a html file, this is the file that would be graded\n",
    "* You can add other files but do not delete any files\n",
    "* Commit your work and push to your private Github repository as explained [here](https://github.com/DSApps-2023/Class_Slides/blob/main/Apps_of_DS_HW.pdf)\n",
    "\n",
    "This assignemtnt is due: TBD\n",
    "\n",
    "### Libraries\n",
    "\n",
    "These are the libraries you will need. If you don't have them, you need to uncomment the `!pip install` line and install them first (you can also just copy this command to a terminal and do it there if you don't want all the output printed in this notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib numpy scipy pandas scikit-learn tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dense, Dropout, Flatten, Input, MaxPool2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where NN beats LM\n",
    "\n",
    "##### (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After our \"Logistic regression as neural network\" section in class, hopefully you know why for a simple binary classification simulated task, logistic regression performs just as well as a neural network.\n",
    "\n",
    "Let's see this in a regression setting!\n",
    "\n",
    "The following function simulates a standard $y = f(X) + \\epsilon$ data, where $\\epsilon_i \\sim N(0,1)$ i.i.d. Its params are:\n",
    "* `N` - no. of observations\n",
    "* `p` - no. of X features (columns), not including intercept\n",
    "* `intercept` - the intercept (e.g. 2.0)\n",
    "* `X_non_linear` - if `False`, then $f(x) = X\\beta$ where $\\beta_j = 1$ for all $j \\in \\{1, \\dots p\\}$ (which means...?), otherwise $f(x) = X\\beta \\cdot cos(X\\beta) + 2 \\cdot X_1 \\cdot X_2$, which is a very not-linear relationship\n",
    "\n",
    "Finally the function returns a testing/training 80/20 split.\n",
    "\n",
    "Go over it, see that you get what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easy_data(N, p, intercept, X_non_linear):\n",
    "    X = np.random.uniform(-1, 1, N * p).reshape((N, p))\n",
    "    betas = np.ones(p)\n",
    "    Xbeta = intercept + X @ betas\n",
    "    epsilon = np.random.normal(0, 1.0, N)\n",
    "    if X_non_linear:\n",
    "        fX = Xbeta * np.cos(Xbeta) + 2 * X[:, 0] * X[:, 1]\n",
    "    else:\n",
    "        fX = Xbeta\n",
    "    y = fX + epsilon\n",
    "    X_df = pd.DataFrame(X)\n",
    "    x_cols = ['X' + str(i) for i in range(p)]\n",
    "    X_df.columns = x_cols\n",
    "    df = pd.concat([pd.DataFrame({'y': y}), X_df], axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.drop('y', axis=1), df['y'], test_size=0.2)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `easy_data()` to generate a **linear** relation between $X$ and $y$, with `N = 10000, p = 10, intercept = 1.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = ### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use [sklearn](https://scikit-learn.org/stable/) to fit a linear model to `X_train, y_train` (Look at the imports). Use this model to predict on `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = ### YOUR CODE HERE ###\n",
    "y_pred = ### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this `mse()` function to get the test MSE on `y_test, y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_test, y_pred):\n",
    "    return np.mean((y_test - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this `plot_reg()` function to plot predicted vs. true $y$s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reg(y_test, y_pred):\n",
    "    min_y = np.min([y_test.min(), y_pred.min()])\n",
    "    max_y = np.max([y_test.max(), y_pred.max()])\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.xlabel('true')\n",
    "    plt.ylabel('pred')\n",
    "    plt.xlim((min_y, max_y))\n",
    "    plt.ylim((min_y, max_y))\n",
    "    plt.axline((min_y, min_y), (max_y, max_y), color='grey') # this line may not work on some versions\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a `mlp(n_neurons)` function which gets a list of integers `n_neurons` and returns a regular Multi-Layer Perceptron (MLP), with a `Dense()` layer for each number of neurons in `n_neurons`, with a ReLU activation. The final layer is a single neuron layer without activation (or `activation='linear'`). Compile the model with a MSE loss and the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(n_neurons):\n",
    "    model = Sequential()\n",
    "    ### YOUR CODE HERE (maybe more than 1 line) ###\n",
    "    model.add(Dense(1))\n",
    "    model.compile(### YOUR CODE HERE ###)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should give us a 2-hidden-layer network with 10 and 5 neurons at each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlp([10, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit `model` on `X_train, y_train`, with 10% validation split, and a `EarlyStopping()` callback where if the validation loss has not decreased in 5 epochs learning is stopped. Use a `batch_size` of 30 and maximum 100 `epochs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [### YOUR CODE HERE ###]\n",
    "history = model.fit(### YOUR CODE HERE ###)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `history` object in the `plot_loss()` function to see that indeed the loss has decreased through the `epochs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('mse')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we predict on `X_test` to get `y_pred`. Use `y_pred` in `mse()` and `plot_reg()` to print the test MSE and plot the $y$s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test).reshape(y_test.shape)\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, hopefully you can see we didn't get any advantage by using a neural network, with a simple linear relationship.\n",
    "\n",
    "BUT!\n",
    "\n",
    "**Repeat everything** we just did only start `easy_data()` asking for a **non-linear** relation between $X$ and $y$ (all else may remain the same). Our DNN, which is a simple MLP, should shine bright (like a diamond)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = ### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE (obviously you will need more than 1 cell to repeat everything) ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moustache!\n",
    "\n",
    "##### (60 points)\n",
    "\n",
    "#### Part A - Getting the data ready\n",
    "\n",
    "The CelebA dataset ([Liu et al. 2015](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)) contains 202,599 cropped facial images from 10,177 celebrities, where each celebrity has between 1 and 35 images, annotated for various attributes (e.g. young or not) and landmarks (e.g. the location of the tip of the nose and mouth).\n",
    "\n",
    "Let's work with the first 10,000 images, you can get them at my Google Drive [here](https://drive.google.com/drive/folders/1bxlahIPmYENc83PXfPBG0t1SFTCy7QIc?usp=sharing). You need the `celeba_small.zip` (570 MB) and you'll also need the `celeba_small.csv` table which is already in your `data` folder.\n",
    "\n",
    "**NOTE 1:** If you're using Google Colab with your own Google identity, you don't actually need to download/upload the `celeba_small.zip` to the notebook environment. You can simply create a shortcut (right-mouse click on file, \"Add a shortcut to drive\"), then you have your own pointer to the zip in *your* drive. Then you can mount your drive to Google Colab, copy the zip to the environment and unzip it there. See e.g. [this](https://stackoverflow.com/a/52300696/4095235) answer.\n",
    "\n",
    "**NOTE 2:** If you're using Google Colab, you might want to change your notebook settings to run on GPU, it will make things faster.\n",
    "\n",
    "Once you get the zip file in this notebook's environment or in the HW7 folder, you can unzip it to get the 10K images in the `img_align_celeba_png` folder with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip celeba_small.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See for example all of [Michael Schumacher](https://en.wikipedia.org/wiki/Michael_Schumacher)'s images (`celeb` no. 1). As you can see all images are pretty much aligned, they have 218 X 178 pixels, 3 color channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df = pd.read_csv('data/celeba_small.csv')\n",
    "\n",
    "images_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Michael's images, celeb no. 1\n",
    "images_df[images_df['celeb'] == 1]['img_file'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = images_df[images_df['celeb'] == 1]['img_file'].to_list()\n",
    "\n",
    "for i, img_file in enumerate(os.listdir('img_align_celeba_png')):\n",
    "    if img_file in query:\n",
    "        img = plt.imread('img_align_celeba_png/' + img_file)\n",
    "        plt.imshow(img)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the `images_df` table there are a few landmarks like `nose_x` and `nose_y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = images_df.columns[1:-1].values\n",
    "landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see some of those on Michael."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "michael_img_file = '000023.png'\n",
    "michael_img = plt.imread('img_align_celeba_png/' + michael_img_file)\n",
    "michael_landmarks = images_df[images_df['img_file'] == img_file][landmarks].values[0]\n",
    "michael_landmarks = np.vstack(np.split(michael_landmarks, 5))\n",
    "x = michael_landmarks[:, 0]\n",
    "y = michael_landmarks[:, 1]\n",
    "plt.imshow(michael_img)\n",
    "plt.scatter(x, y, color='black', marker='+', s=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's an image of a moustache..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moustache = plt.imread('images/moustache.png')\n",
    "plt.imshow(moustache)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we, using his landmarks, put a moustache on Michael?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "michael_landmarks = dict(zip(landmarks, images_df[images_df['img_file'] == img_file][landmarks].values[0]))\n",
    "michael_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moustach_borders = [michael_landmarks['leftmouth_x'], michael_landmarks['rightmouth_x'],\n",
    "                      michael_landmarks['nose_y'], michael_landmarks['leftmouth_y']]\n",
    "plt.imshow(moustache, extent=moustach_borders, zorder=2)\n",
    "plt.imshow(michael_img, zorder=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put it in a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_landmarks = dict(zip(landmarks, images_df[images_df['img_file'] == michael_img_file][landmarks].values[0]))\n",
    "\n",
    "def draw_moustache(img_file, person_landmarks, images_dir='img_align_celeba_png/'):\n",
    "    person_img = plt.imread(images_dir + img_file)\n",
    "    moustach_borders = [person_landmarks['leftmouth_x'], person_landmarks['rightmouth_x'],\n",
    "                      person_landmarks['nose_y'], person_landmarks['leftmouth_y']]\n",
    "    plt.imshow(moustache, extent=moustach_borders, zorder=2)\n",
    "    plt.imshow(person_img, zorder=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [8, 5, 9]:\n",
    "    img_file = '00000' + str(i) + '.png'\n",
    "    person_landmarks = dict(zip(landmarks, images_df[images_df['img_file'] == img_file][landmarks].values[0]))\n",
    "    draw_moustache(img_file, person_landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice in the `draw_moustache()` function, we only need 4 landmarks: `'leftmouth_x', 'rightmouth_x', 'nose_y', 'leftmouth_y'`.\n",
    "\n",
    "What I want you to do is train a convolutional neural network (CNN) which would predict these 4 landmarks from an image, and will allow us to automatically put this Snapchat-like moustache mask on unseen faces!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to get all images for training, if you have enough RAM, you can actually do a similar procedure to what  we did in class with the `malaria` dataset. You will get a 4.65 gigabytes `X` float `np.array()`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = []\n",
    "\n",
    "# for img_file in images_df['img_file']:\n",
    "#     images.append(plt.imread('img_align_celeba_png/' + img_file))\n",
    "\n",
    "# X = np.array(images)\n",
    "\n",
    "# required_landmarks = ['leftmouth_x', 'rightmouth_x', 'nose_y', 'leftmouth_y']\n",
    "# y = images_df[required_landmarks]\n",
    "\n",
    "# print(X.shape) # (10000, 218, 178, 3)\n",
    "# print(y.shape) # (10000, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there's no need for that, and I want you to be ready to train on millions of images. Remember the real CelebA dataset has over 200K!\n",
    "\n",
    "So we need a `ImageDataGenerator()`. Notice here we do not perform any image augmentation, only rescale the image arrays to be between 0 and 1, and asking the `train_datagen` to have a `validation_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 218\n",
    "IMG_WIDTH = 178\n",
    "batch_size = 30\n",
    "epochs = 100\n",
    "images_dir = 'img_align_celeba_png/'\n",
    "required_landmarks = ['leftmouth_x', 'rightmouth_x', 'nose_y', 'leftmouth_y']\n",
    "\n",
    "train_datagen = ImageDataGenerator(validation_split=0.1, rescale = 1. / 255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1. / 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in class you've seen the `flow_from_directory()` method of the generator, uploading from train/valid/test directory each time the required batch of images, preprocessing it and training/predicting on it.\n",
    "\n",
    "Let's use the `flow_from_dataframe()` method, which is more suitable when you have a DataFrame of additional data like we do, and your images aren't divided into separate directories.\n",
    "\n",
    "Here we need to give each generator:\n",
    "* the `dataframe` (which we get by properly filtering the train/test samples)\n",
    "* the `directory` in which to find the images\n",
    "* `x_col` which is the column in the DataFrame in which to find the images names\n",
    "* `y_col` which is 1 or more label columns (we have 4!)\n",
    "* `target_size`, the required dimensions of the image\n",
    "* `class_mode`, we use `\"raw\"` for regression\n",
    "* `batch_size`\n",
    "* `shuffle` - notice there's no need to shuffle validation or testing sets\n",
    "* `subset` - this allows to not define separate `datagen`s for training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp, test_samp = train_test_split(np.arange(images_df.shape[0]), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe = images_df[images_df.index.isin(train_samp)],\n",
    "    directory = images_dir,\n",
    "    x_col = 'img_file',\n",
    "    y_col = required_landmarks,\n",
    "    target_size = (IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode = 'raw',\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    subset = 'training',\n",
    "    validate_filenames = False\n",
    ")\n",
    "valid_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe = images_df[images_df.index.isin(train_samp)],\n",
    "    directory = images_dir,\n",
    "    x_col = 'img_file',\n",
    "    y_col = required_landmarks,\n",
    "    target_size = (IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode = 'raw',\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False,\n",
    "    subset = 'validation',\n",
    "    validate_filenames = False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe = images_df[images_df.index.isin(test_samp)],\n",
    "    directory = images_dir,\n",
    "    x_col = 'img_file',\n",
    "    y_col = required_landmarks,\n",
    "    target_size = (IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode = 'raw',\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False,\n",
    "    validate_filenames = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put it in a function, `get_generators()` which would get `train_samp` (sample of training indices), `test_samp` (sample of testing indices) and `validation_split`, we'll use it later (Yes, it's basically copy-paste)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generators(train_samp, test_samp, validation_split = 0.1):\n",
    "    ### YOUR CODE HERE ###\n",
    "    return train_generator, valid_generator, test_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part B - Bad CNN!\n",
    "\n",
    "Finally, you get to do something!\n",
    "\n",
    "You are going to use the Functional API to implement the `cnn()` which should return a compiled CNN, with the following architecture:\n",
    "* `Input()` layer, where you only need to specify the input shape (it is the shape of an image, `(IMG_HEIGHT, IMG_WIDTH, 3)`)\n",
    "* `Conv2D()` layer, with 32 kernels, (5, 5) strides, padding valid, ReLU activation\n",
    "* `MaxPool2D()` layer, with (2, 2) pool size\n",
    "* `Conv2D()` layer, with 64 kernels, (5, 5) strides, padding valid, ReLU activation\n",
    "* `MaxPool2D()` layer, with (2, 2) pool size\n",
    "* `Conv2D()` layer, with 32 kernels, (5, 5) strides, padding valid, ReLU activation\n",
    "* `MaxPool2D()` layer, with (2, 2) pool size\n",
    "* `Conv2D()` layer, with 16 kernels, (5, 5) strides, padding valid, ReLU activation\n",
    "* `MaxPool2D()` layer, with (2, 2) pool size\n",
    "* `Flatten()` layer\n",
    "* `Dropout()` layer of 50%\n",
    "* Fully connected layer of 100 neurons and ReLU activation\n",
    "* Fully connected layer with 4 neurons and no activation. This is the output layer.\n",
    "* Use optimizer `'adam'` and loss `'mse'`\n",
    "\n",
    "Why this model? I literally just copy-pasted it from some blog, as you might be inclined to do (it will get better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn():\n",
    "    ### YOUR CODE HERE ###\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you fit the model, show me a good baseline test MSE, above it you could say our network is quite bad:\n",
    "\n",
    "(Hint: `test_generator.labels`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, fit the model. Notice how we're using the same `fit()` method of the `model` which works the same on generators. I also want you to keep `verbose=1` to see the somewhat annoying print.\n",
    "\n",
    "This should run for 20-50 epochs, each epoch should take ~30-60 seconds on a decent GPU. You should get a `val_loss` of about 10-20 pixels MSE. Is this a \"good\" loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
    "\n",
    "history = model.fit(train_generator, \n",
    "                    validation_data = valid_generator,\n",
    "                    epochs=epochs, callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict $y$, notice we get a 4-column prediction array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the test MSE (use `model.evaluate(...)`, it would be easiest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot one of `y_pred` against the relevant `y_test` (see hint above). You should be very not-impressed :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, the CNN predicted for each $y$ no better than the mean, and even slightly worse!\n",
    "\n",
    "But you know what? Run this to get some moustaches and see that the mean isn't actually that bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    img_file = test_generator.filenames[i]\n",
    "    person_landmarks = dict(zip(required_landmarks, y_pred[i, :]))\n",
    "    draw_moustache(img_file, person_landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the default printing with `verbose=1` is a bit annoying. You are going to implement a custom callback `BetterLossPrint()` which would print the epoch number, only the monitred loss (`'loss'` or `'val_loss'`), whether it has `DECREASED` or `INCREASED` from the last epoch, the best loss so far and how many epochs have passed since we have not seen a decrease in best loss.\n",
    "\n",
    "You don't get any hints beside the proper [documentation](https://www.tensorflow.org/guide/keras/custom_callback), because that's life. See below how it is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetterLossPrint(Callback):\n",
    "    \"\"\"\n",
    "    Prints at each epoch's end the epoch number, monitored loss, whether it has DECREASED/INCREASED from last epoch,\n",
    "    best loss so far and no. of epochs since we've seen it\n",
    "    \"\"\"\n",
    "    def __init__(self, monitor):\n",
    "        super(BetterLossPrint, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        \n",
    "    ### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now re-instantiate the model and fit it with `verbose=0` and use your custom callback **only**, meaning this would run for `epochs=10` iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn()\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "callbacks = [BetterLossPrint(monitor = 'val_loss')]\n",
    "\n",
    "history = model.fit(train_generator, \n",
    "                    validation_data = valid_generator,\n",
    "                    epochs=epochs, callbacks=callbacks, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part C - Tuning CNN\n",
    "\n",
    "So our model is pretty bad. It desparately needs tuning.\n",
    "\n",
    "If it were a simple Sequential API without generators, we could use `GridSearchCV()` from sklearn to do something similar to what we did in class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# def cnn_with_tuning(n_conv_layers, n_kernels, stride, dropout):\n",
    "#     ### define model\n",
    "#     return model\n",
    "\n",
    "# keras_reg = KerasRegressor(cnn_with_tuning)\n",
    "\n",
    "# params = {\n",
    "#     'n_conv_layers': [1,3,5],\n",
    "#     'n_kernels': [10,20,30],\n",
    "#     'stride': [2,5],\n",
    "#     'dropout': [True, False]\n",
    "# }\n",
    "\n",
    "# grid_search_cv = GridSearchCV(keras_reg, params, cv=5, verbose=4)\n",
    "\n",
    "# grid_search_cv.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     validation_split = 0.1,\n",
    "#     epochs=10, callbacks=callbacks, verbose=0\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately `GridSearchCV()` does not work well with generator, without a proper wrapper.\n",
    "\n",
    "Let's go manual!\n",
    "\n",
    "Implement `cnn_with_tuning()` which receives the `n_conv_layers, n_kernels, stride, dropout` params. It should be very similar to `cnn()` only you start with a pair of `Conv2D(...)` and `MaxPool2D((2, 2))`, then add `n_conv_layers - 1` more pairs of these, before compiling and returning the model as before.\n",
    "\n",
    "* You can assume `n_conv_layers` >= 1\n",
    "* Notice the `Conv2D()` params no. of kernels/features and stride size are no longer fixed, they're being tuned, yet **use the same in each `Conv2D()`**\n",
    "* And `dropout` is either `True` or `False`, i.e. it should be an optional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_with_tuning(n_conv_layers, n_kernels, stride, dropout):\n",
    "    ### YOUR CODE HERE ###\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a possible `dict()` of params to try at each combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_conv_layers': [1,3,5],\n",
    "    'n_kernels': [10,20,30],\n",
    "    'stride': [2,5],\n",
    "    'dropout': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we get a `KFold()` object from sklearn. We're asking for 5 folds without shuffling. We also make `epochs` to a fixed 10 (no `EarlyStopping()`) and initialize an empty DataFrame of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "epochs = 10\n",
    "res_df = pd.DataFrame(columns = list(params.keys()) + ['fold', 'mse'])\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we're taking all combinations in `params` across 5 folds. Calculate how many `model`s are going to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the quick math and see how long this is going to take. If it is absurd, you can decrease no. of epochs or remove some values in `params`, but specify what you're doing. I want to see you know how to do this, not that you have a fancy GPU or can wait a long time...\n",
    "\n",
    "Now go ahead and fill in the blanks to run this grid search manually.\n",
    "\n",
    "**Note:**\n",
    "* Run the grid search only on the training data! The training data has indices `train_samp`, 8000 rows.\n",
    "* You run for a fixed no. of `epochs` always, you don't need `validation_data`!\n",
    "* If you're using the `BetterLossPrint()` you will need to monitor `'loss'`, not `'val_loss'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_conv_layers in params['n_conv_layers']:\n",
    "    for n_kernels in params['n_kernels']:\n",
    "        for stride in params['stride']:\n",
    "            for dropout in params['dropout']:\n",
    "                print()\n",
    "                print(f'n_conv_layers: {n_conv_layers}; n_kernels: {n_kernels}; stride: {stride}; dropout: {dropout}')\n",
    "                for fold, (train_index, test_index) in enumerate(kf.split(train_samp)):\n",
    "                    print(f'  Fold: {fold}')\n",
    "                    model = ### YOUR CODE HERE ###\n",
    "                    train_generator, _, test_generator = ### YOUR CODE HERE ###\n",
    "                    history = model.fit(### YOUR CODE HERE ###)\n",
    "                    mse_fold = model.evaluate(test_generator, verbose=0)\n",
    "                    res_df.loc[counter] = [n_conv_layers, n_kernels, stride, dropout, fold, mse_fold]\n",
    "                    counter += 1           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at `res_df`, show me by either a good summary, a visualization, or both, what are the best params, expected to reach the lowest MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BTW, you can look at *my* resulting DataFrame in file `data/moustache_cv.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, choose the best params and run on the entire training set, predict on the test set, show us proper plots to see that indeed we get a much better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, draw someone a moustache! No, seriously, take Amir Peretz's image in `images/peretz.png`, read it, predict landmarks, give him back his moustache and see that it makes sense.\n",
    "\n",
    "Notice that when you read an image you get a 3D array, but `model` expects a 4D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper questions\n",
    "\n",
    "##### (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the first 7 pages of [LassoNet](https://www.jmlr.org/papers/v22/20-848.html) (Lemhadri et al., JMLR 2021). Of course you're welcome to read the whole thing!\n",
    "\n",
    "In class we mentioned regularizing the network's weights using e.g. `kernel_regularizer=regularizers.l1(0.01)` inside a `Dense()` layer. But this! This is something entirely different, isn't it? Explain in your own words what is LassoNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the **main** difference between the loss optimized in the following model and the LassoNet loss (p. 6 eq. (2))?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notLassoNet(p):\n",
    "    input_layer = Input((p,))\n",
    "    x1 = Dense(1, activation='linear', kernel_regularizer= regularizers.l1(0.01))(input_layer)\n",
    "    x2 = Dense(p, activation='relu')(input_layer)\n",
    "    x2 = Dense(1)(x2)\n",
    "    output_layer = Add()([x1, x2])\n",
    "    model = Model(input_layer, output_layer)\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap up\n",
    "\n",
    "And that's it, you've implemented common DNNs such as a MLP and a CNN. You've seen where NN beats a simple linear model, you've implemented a custom callback, you tuned params - you did quite a lot! Good luck with the Final Project!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
